{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "![](./figs/External_Attention.png)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3a8e3fcc4f4882ea"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Linear(in_features=64, out_features=32, bias=True)\n",
      "0 Linear(in_features=32, out_features=64, bias=True)\n",
      "0 Softmax(dim=1)\n",
      "0 ExternalAttention(\n",
      "  (mk): Linear(in_features=64, out_features=32, bias=True)\n",
      "  (mv): Linear(in_features=32, out_features=64, bias=True)\n",
      "  (softmax): Softmax(dim=1)\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": "ExternalAttention(\n  (mk): Linear(in_features=64, out_features=32, bias=True)\n  (mv): Linear(in_features=32, out_features=64, bias=True)\n  (softmax): Softmax(dim=1)\n)"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "\n",
    "class ExternalAttention(nn.Module):\n",
    "    def __init__(self, input_dim=64,output_dim=32):\n",
    "        super().__init__()\n",
    "        self.mk = nn.Linear(input_dim,output_dim)\n",
    "        self.mv = nn.Linear(output_dim,input_dim)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        self.init_weights()\n",
    "        \n",
    "    def init_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m,nn.Conv2d):\n",
    "                init.xavier_uniform_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    init.constant_(m.bias,0)\n",
    "            elif isinstance(m,nn.BatchNorm2d):\n",
    "                init.constant_(m.weight,1)\n",
    "                init.constant_(m.weight,0)\n",
    "            elif isinstance(m,nn.Linear):\n",
    "                init.normal_(m.weight,std=1e-3)\n",
    "                if m.bias is not None:\n",
    "                    init.constant_(m.bias, 0)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        attn = self.mk(x)\n",
    "        attn = self.softmax(attn)\n",
    "        attn = attn / torch.sum(attn,dim=2,keepdim=True)\n",
    "        out = self.mv(attn)\n",
    "        return out\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-15T12:07:12.729044700Z",
     "start_time": "2024-02-15T12:07:12.630796500Z"
    }
   },
   "id": "fae46af241182582",
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "3283d95f6d5c7cfa"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10% 1/10 [00:01<00:09,  1.00s/it, index=0]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20% 2/10 [00:02<00:08,  1.00s/it, index=1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30% 3/10 [00:03<00:07,  1.00s/it, index=2]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40% 4/10 [00:04<00:06,  1.00s/it, index=3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50% 5/10 [00:05<00:05,  1.00s/it, index=4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60% 6/10 [00:06<00:04,  1.00s/it, index=5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70% 7/10 [00:07<00:03,  1.00s/it, index=6]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80% 8/10 [00:08<00:02,  1.00s/it, index=7]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90% 9/10 [00:09<00:01,  1.00s/it, index=8]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 10/10 [00:10<00:00,  1.00s/it, index=9]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import time\n",
    "pbar = tqdm(range(10),ncols=0)\n",
    "for i in pbar:\n",
    "    time.sleep(1)\n",
    "    print(i)\n",
    "    pbar.set_postfix(index=i)\n",
    "pbar.close()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-15T14:42:56.899885500Z",
     "start_time": "2024-02-15T14:42:46.824180300Z"
    }
   },
   "id": "655affd8b371d33e",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'state': {}, 'param_groups': [{'lr': 0.001, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0.0001, 'amsgrad': False, 'maximize': False, 'foreach': None, 'capturable': False, 'differentiable': False, 'fused': None, 'params': [0, 1]}]}\n",
      "{'step_size': 3, 'gamma': 0.5, 'base_lrs': [0.001], 'last_epoch': 0, 'verbose': False, '_step_count': 1, '_get_lr_called_within_step': False, '_last_lr': [0.001]}\n",
      "0.001\n",
      "0.000125\n",
      "0.000125\n",
      "0.000125\n",
      "6.25e-05\n",
      "6.25e-05\n",
      "6.25e-05\n",
      "3.125e-05\n",
      "3.125e-05\n",
      "3.125e-05\n",
      "{'step_size': 3, 'gamma': 0.5, 'base_lrs': [0.001], 'last_epoch': 18, 'verbose': False, '_step_count': 11, '_get_lr_called_within_step': False, '_last_lr': [1.5625e-05]}\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "from torch.optim import lr_scheduler\n",
    "model = nn.Conv2d(10,20,3)\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=1e-3,weight_decay=1e-4)\n",
    "print(optimizer.state_dict())\n",
    "\n",
    "lr_scheduler = lr_scheduler.CosineAnnealingLR(optimizer,step_size=3,gamma=0.5)\n",
    "print(lr_scheduler.state_dict())\n",
    "for epoch in range(10):\n",
    "    optimizer.zero_grad()\n",
    "    print(optimizer.param_groups[0][\"lr\"])\n",
    "    optimizer.step()\n",
    "    lr_scheduler.step(9+epoch)\n",
    "print(lr_scheduler.state_dict())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-15T15:27:18.161489Z",
     "start_time": "2024-02-15T15:27:18.126859600Z"
    }
   },
   "id": "293afe6f6f61584b",
   "execution_count": 23
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
